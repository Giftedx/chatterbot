# Discord Bot Configuration
# Get these from https://discord.com/developers/applications
DISCORD_TOKEN=your_discord_bot_token_here
DISCORD_CLIENT_ID=your_discord_client_id_here

# Google Gemini AI Configuration
# Get this from https://makersuite.google.com/app/prompts/new_freeform
GEMINI_API_KEY=your_gemini_api_key_here

# Environment Configuration
NODE_ENV=production

# Core feature flags
# Enhanced intelligence enables MCP-backed features and related optimizations
ENABLE_ENHANCED_INTELLIGENCE=true
# Agentic intelligence enables agentic commands and behaviors
ENABLE_AGENTIC_INTELLIGENCE=true

# Built-in Analytics Dashboard
# This controls the internal lightweight dashboard server
ENABLE_ANALYTICS_DASHBOARD=false
ANALYTICS_DASHBOARD_PORT=3001

# Legacy/compat feature flags referenced by tests and legacy docs
# Note: ENABLE_ANALYTICS is NOT used by the runtime dashboard (use ENABLE_ANALYTICS_DASHBOARD above)
# and ENABLE_MCP_INTEGRATION is implied by ENABLE_ENHANCED_INTELLIGENCE.
ENABLE_ANALYTICS=false
ENABLE_MCP_INTEGRATION=true

# Enhanced Intelligence API Keys (for real MCP integration)
BRAVE_API_KEY=your_brave_search_api_key_here
FIRECRAWL_API_KEY=your_firecrawl_api_key_here

# Media & Speech Providers (optional)
# Stability AI for image generation
STABILITY_API_KEY=your_stability_ai_api_key_here
# Tenor for GIF search
TENOR_API_KEY=your_tenor_api_key_here
# ElevenLabs for TTS
ELEVENLABS_API_KEY=your_elevenlabs_api_key_here
ELEVENLABS_VOICE_ID=21m00Tcm4TlvDq8ikWAM

# Agentic Intelligence Configuration
# These are used when agentic features are enabled
AGENTIC_CHANNELS=channel_id_1,channel_id_2
AGENTIC_ESCALATION_CHANNEL=moderator_channel_id
AGENTIC_MODERATOR_ROLES=moderator_role_id_1,moderator_role_id_2

# Database Configuration
# SQLite (Prisma) default for app data.
# For local dev, set to file:./prisma/dev.db. Docker Compose overrides to file:/data/dev.db at runtime.
DATABASE_URL=file:./prisma/dev.db

# Postgres (optional) for pgvector/vector store features.
# Do NOT set DATABASE_URL to Postgres unless you intentionally migrate Prisma to Postgres.
POSTGRES_URL=postgresql://chatterbot:chatterbot@postgres:5432/chatterbot
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=chatterbot
POSTGRES_USER=chatterbot
POSTGRES_PASSWORD=chatterbot
POSTGRES_SSL=false

# Health Check Configuration
HEALTH_CHECK_PORT=3000

# Logging Configuration
LOG_LEVEL=info

# Rate Limiting (Optional)
MAX_REQUESTS_PER_MINUTE=60
MAX_REQUESTS_PER_HOUR=1000

# Feature Flags (additional advanced features; optional)
ENABLE_MODERATION=true
ENABLE_MCP_INTEGRATION=true
# Advanced conversational capabilities
ENABLE_SELF_CRITIQUE=true
ENABLE_HYBRID_RETRIEVAL=true
ENABLE_WEB_GROUNDING=true
ENABLE_AUTO_MEMORY=true

# Ultra-Intelligence System Configuration
# Enables the complete ultra-intelligent Discord AI system
ENABLE_ULTRA_INTELLIGENCE=true

# Advanced Memory & Social Intelligence
ENABLE_EPISODIC_MEMORY=true
ENABLE_SOCIAL_INTELLIGENCE=true
ENABLE_EMOTIONAL_INTELLIGENCE=true
MAX_MEMORIES_PER_USER=1000
MEMORY_DECAY_RATE=0.01
MEMORY_IMPORTANCE_THRESHOLD=0.3
MEMORY_CONSOLIDATION_INTERVAL=3600000
SOCIAL_ANALYSIS_DEPTH=moderate
EMOTIONAL_SENSITIVITY=0.7
ADAPTATION_AGGRESSIVENESS=0.6

# Autonomous Reasoning Configuration
ENABLE_AUTONOMOUS_REASONING=true
AUTONOMOUS_REFLECTION_FREQUENCY=30
AUTONOMOUS_GOAL_EVALUATION_INTERVAL=60
AUTONOMOUS_PERSONA_ADAPTATION_THRESHOLD=0.7
AUTONOMOUS_MAX_ACTIVE_GOALS=5

# Ultra-Intelligent Research Configuration
ENABLE_ULTRA_RESEARCH=true
RESEARCH_CACHE_DURATION=7200000
RESEARCH_MAX_SOURCES=15
RESEARCH_VERIFICATION_LEVEL=standard

# Human-Like Conversation Configuration
ENABLE_HUMAN_CONVERSATION=true
CONVERSATION_ADAPTATION_SPEED=0.7
CONVERSATION_CREATIVITY_LEVEL=0.8
CONVERSATION_SOCIAL_AWARENESS=0.9
CONVERSATION_EXPERTISE_CONFIDENCE=0.8

# Ultra-Intelligence Behavioral Settings
ULTRA_INTELLIGENCE_PREFERRED_PERSONALITY=adaptive
ULTRA_INTELLIGENCE_MAX_PROCESSING_TIME=30000
ULTRA_INTELLIGENCE_ENABLE_REAL_TIME_LEARNING=true
ULTRA_INTELLIGENCE_ENABLE_PROACTIVE_INSIGHTS=true
ULTRA_INTELLIGENCE_ENABLE_MULTIMODAL_PROCESSING=true
ULTRA_INTELLIGENCE_ENABLE_SERVER_CULTURE_ADAPTATION=true
ULTRA_INTELLIGENCE_ENABLE_USER_RELATIONSHIP_MEMORY=true
ULTRA_INTELLIGENCE_ENABLE_CONTINUOUS_IMPROVEMENT=true

# Security Note: Documentation Updates
# Documentation updates should NOT be controlled by runtime environment variables
# as this creates potential security risks in production environments.
# Instead, use build/deployment scripts to update documentation.
# Example: Use CI/CD pipelines, build scripts, or deployment automation
# to handle documentation updates as part of the deployment process.

# Optional: Multi-provider model routing
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-latest
DEFAULT_PROVIDER=gemini

# Additional Providers
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.1-70b-versatile
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_MODEL=mistral-large-latest
OPENAI_COMPAT_API_KEY=your_openai_compatible_api_key_here
OPENAI_COMPAT_BASE_URL=https://your-openai-compatible-endpoint/v1
OPENAI_COMPAT_MODEL=qwen2.5-32b-instruct

# Verification and Auto-Rerun
ENABLE_ANSWER_VERIFICATION=true
CROSS_MODEL_VERIFICATION=true
MAX_RERUNS=1

# Orchestration & AI SDK feature flags
FEATURE_TEMPORAL=false
FEATURE_VERCEL_AI=false
FEATURE_PGVECTOR=false
FEATURE_LANGGRAPH=false
FEATURE_OPENAI_RESPONSES=false
FEATURE_OPENAI_RESPONSES_TOOLS=false
FEATURE_TOOL_SUMMARY=false
FEATURE_RERANK=false
FEATURE_PERSIST_TELEMETRY=false
COST_TIER_MAX=medium
SPEED_TIER_MIN=medium
AI_API_KEY=your_vercel_ai_sdk_key_here
# Temporal Orchestration
TEMPORAL_TASK_QUEUE=discord-ai-bot
TEMPORAL_ADDRESS=127.0.0.1:7233
# Maintenance intervals
MEMORY_CONSOLIDATION_INTERVAL=3600000
VECTOR_MAINTENANCE_INTERVAL=21600000
KB_CHUNK_TTL_DAYS=180

# Optional: Cohere for reranking
COHERE_API_KEY=your_cohere_api_key_here

# Optional: Provider preference can be set per-request via /chat provider option.

# Edge AI deployment
EDGE_MAX_NODES=5
EDGE_LOAD_THRESHOLD=0.8
EDGE_SYNC_INTERVAL_MS=30000
EDGE_FAILOVER_ENABLED=true
EDGE_MODEL_REPLICATION=2
EDGE_UPTIME_SUCCESS_RATE=0.95
EDGE_MAX_SIMULATED_LOAD_FACTOR=0.9

# Streaming/Auth
# Real-time service expects a token starting with 'user_' via query (?token=) or Authorization: Bearer <token>

# OpenTelemetry exporter endpoint
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318/v1/traces
