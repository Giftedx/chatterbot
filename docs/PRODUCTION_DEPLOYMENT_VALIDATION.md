# Production Deployment Validation

This document provides comprehensive validation procedures for ensuring Chatterbot is production-ready with all AI enhancement services properly configured and functioning.

## Overview

The production validation process validates 8 critical areas:
1. **Environment Configuration** - Required and recommended environment variables
2. **Code Compilation** - TypeScript compilation and dependency validation
3. **Service Availability** - All 17 AI enhancement services and core components
4. **Feature Flag Configuration** - Proper feature flag settings for production
5. **Database Setup** - Database connectivity and migration status
6. **Performance Configuration** - Monitoring thresholds and alerting setup
7. **Load Handling** - Concurrent request processing capabilities
8. **Security Validation** - Security best practices and credential validation

## Quick Validation

### Automated Production Validation Script

Run the comprehensive validation script:

```bash
# Make script executable
chmod +x scripts/production-validation.js

# Run full production validation
node scripts/production-validation.js

# The script will generate a detailed report and exit with:
# - Exit code 0: Production ready
# - Exit code 1: Issues found, not production ready
```

### Manual Pre-Deployment Checklist

```bash
# 1. Environment validation
npm run config:check

# 2. TypeScript compilation
npm run build

# 3. Database migrations
npx prisma migrate deploy

# 4. Service health check
npm run health:check

# 5. Performance monitoring test
npm run performance:test

# 6. Load test (optional)
npm run load:test
```

## Detailed Validation Procedures

### 1. Environment Configuration Validation

#### Required Environment Variables
These variables MUST be present for production deployment:

```bash
# Core Discord Configuration
DISCORD_TOKEN=your_discord_bot_token
DISCORD_CLIENT_ID=your_discord_client_id

# AI Provider (at least one required)
GEMINI_API_KEY=your_gemini_api_key

# Environment Settings
NODE_ENV=production
DATABASE_URL=file:/data/production.db
```

#### Production-Recommended Variables
For full AI enhancement capabilities:

```bash
# Additional AI Providers
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
GROQ_API_KEY=your_groq_api_key

# Observability
LANGFUSE_PUBLIC_KEY=pk_production_key
LANGFUSE_SECRET_KEY=sk_production_key

# External Services
REDIS_URL=redis://redis:6379
NEO4J_URI=bolt://neo4j:7687
QDRANT_URL=http://qdrant:6333

# Performance Monitoring
ENABLE_PERFORMANCE_MONITORING=true
PERFORMANCE_ALERT_THRESHOLD_ERROR_RATE=0.05
PERFORMANCE_ALERT_THRESHOLD_RESPONSE_TIME=5000
PERFORMANCE_RETENTION_HOURS=168
```

#### Validation Commands
```bash
# Check required variables
echo "Checking required environment variables..."
for var in DISCORD_TOKEN DISCORD_CLIENT_ID GEMINI_API_KEY NODE_ENV DATABASE_URL; do
  if [ -z "${!var}" ]; then
    echo "‚ùå Missing: $var"
  else
    echo "‚úÖ Set: $var"
  fi
done

# Validate NODE_ENV
if [ "$NODE_ENV" = "production" ]; then
  echo "‚úÖ NODE_ENV is production"
else
  echo "‚ö†Ô∏è  NODE_ENV is $NODE_ENV (expected: production)"
fi
```

### 2. Service Availability Validation

#### Core Services Checklist
Verify all critical services are available:

```bash
# Core Intelligence Service
[ -f "src/services/core-intelligence.service.ts" ] && echo "‚úÖ Core Intelligence" || echo "‚ùå Core Intelligence"

# Performance Monitoring
[ -f "src/services/performance-monitoring.service.ts" ] && echo "‚úÖ Performance Monitoring" || echo "‚ùå Performance Monitoring"

# Enhanced Observability
[ -f "src/services/enhanced-langfuse.service.ts" ] && echo "‚úÖ Enhanced Observability" || echo "‚ùå Enhanced Observability"
```

#### AI Enhancement Services Checklist
Verify all 17 AI enhancement services:

```bash
# Create service validation script
cat > check-services.sh << 'EOF'
#!/bin/bash
services=(
  "sentiment-analysis"
  "context-memory" 
  "conversation-summarization"
  "intent-recognition"
  "response-personalization"
  "learning-system"
  "conversation-threading"
  "qdrant-vector"
  "neo4j-knowledge-graph"
  "qwen-vl-multimodal"
  "crawl4ai-web"
  "dspy-rag-optimization"
  "ai-evaluation"
)

for service in "${services[@]}"; do
  file="src/services/${service}.service.ts"
  if [ -f "$file" ]; then
    echo "‚úÖ $service"
  else
    echo "‚ùå $service (missing: $file)"
  fi
done
EOF

chmod +x check-services.sh
./check-services.sh
```

### 3. Feature Flag Configuration Validation

#### Core Feature Flags (Production Required)
```bash
# Core AI Capabilities - Should be enabled in production
export ENABLE_ENHANCED_INTELLIGENCE=true
export ENABLE_AGENTIC_INTELLIGENCE=true
export ENABLE_ANSWER_VERIFICATION=true
export CROSS_MODEL_VERIFICATION=true

# Validate core flags
for flag in ENABLE_ENHANCED_INTELLIGENCE ENABLE_AGENTIC_INTELLIGENCE ENABLE_ANSWER_VERIFICATION; do
  if [ "${!flag}" = "true" ]; then
    echo "‚úÖ $flag: enabled"
  else
    echo "‚ö†Ô∏è  $flag: ${!flag:-'not set'} (should be 'true' for production)"
  fi
done
```

#### AI Enhancement Service Flags
```bash
# Production AI Enhancement Services (enable as needed)
ai_services=(
  "ENABLE_PERFORMANCE_MONITORING"
  "ENABLE_SENTIMENT_ANALYSIS"
  "ENABLE_CONTEXT_MEMORY"
  "ENABLE_CONVERSATION_SUMMARIZATION"
  "ENABLE_INTENT_RECOGNITION"
  "ENABLE_RESPONSE_PERSONALIZATION"
  "ENABLE_LEARNING_SYSTEM"
  "ENABLE_CONVERSATION_THREADING"
  "ENABLE_QDRANT_INTEGRATION"
  "ENABLE_KNOWLEDGE_GRAPH"
  "ENABLE_MULTIMODAL_PROCESSING"
  "ENABLE_WEB_CRAWLING"
  "ENABLE_RAG_OPTIMIZATION"
  "ENABLE_AI_EVALUATION"
  "ENABLE_PREDICTIVE_RESPONSES"
)

enabled_count=0
for service in "${ai_services[@]}"; do
  if [ "${!service}" = "true" ]; then
    echo "‚úÖ $service: enabled"
    ((enabled_count++))
  else
    echo "‚ÑπÔ∏è  $service: disabled"
  fi
done

total_services=${#ai_services[@]}
percentage=$(( (enabled_count * 100) / total_services ))
echo "üìä AI Services enabled: $enabled_count/$total_services ($percentage%)"
```

### 4. Database Validation

#### SQLite Validation (Default)
```bash
# Check SQLite database file exists and is accessible
if [ -f "${DATABASE_URL#file:}" ]; then
  echo "‚úÖ SQLite database file exists"
  
  # Check if file is writable
  if [ -w "${DATABASE_URL#file:}" ]; then
    echo "‚úÖ Database is writable"
  else
    echo "‚ùå Database is not writable"
  fi
else
  echo "‚ö†Ô∏è  Database file doesn't exist yet (will be created on first run)"
fi

# Check Prisma schema
if [ -f "prisma/schema.prisma" ]; then
  echo "‚úÖ Prisma schema exists"
else
  echo "‚ùå Prisma schema missing"
fi

# Generate Prisma client
if npx prisma generate > /dev/null 2>&1; then
  echo "‚úÖ Prisma client generation successful"
else
  echo "‚ùå Prisma client generation failed"
fi

# Check migration status
migration_status=$(npx prisma migrate status 2>&1)
if echo "$migration_status" | grep -q "Database is up to date"; then
  echo "‚úÖ Database migrations are up to date"
elif echo "$migration_status" | grep -q "need to be applied"; then
  echo "‚ö†Ô∏è  Database migrations need to be applied"
  echo "Run: npx prisma migrate deploy"
else
  echo "‚ÑπÔ∏è  Migration status unclear (new database)"
fi
```

#### PostgreSQL Validation (Optional)
```bash
# Only run if pgvector is enabled
if [ "$FEATURE_PGVECTOR" = "true" ]; then
  echo "Validating PostgreSQL configuration..."
  
  # Check PostgreSQL connection variables
  for var in POSTGRES_HOST POSTGRES_PORT POSTGRES_DB POSTGRES_USER POSTGRES_PASSWORD; do
    if [ -n "${!var}" ]; then
      echo "‚úÖ $var is set"
    else
      echo "‚ö†Ô∏è  $var not set (may use DATABASE_URL or POSTGRES_URL)"
    fi
  done
  
  # Test PostgreSQL connection (if psql is available)
  if command -v psql > /dev/null 2>&1; then
    if psql "$POSTGRES_URL" -c "SELECT version();" > /dev/null 2>&1; then
      echo "‚úÖ PostgreSQL connection successful"
      
      # Check pgvector extension
      if psql "$POSTGRES_URL" -c "SELECT * FROM pg_extension WHERE extname = 'vector';" | grep -q "vector"; then
        echo "‚úÖ pgvector extension is installed"
      else
        echo "‚ö†Ô∏è  pgvector extension not found"
      fi
    else
      echo "‚ùå PostgreSQL connection failed"
    fi
  else
    echo "‚ÑπÔ∏è  psql not available, skipping connection test"
  fi
fi
```

### 5. Performance Configuration Validation

#### Performance Monitoring Thresholds
```bash
# Validate performance monitoring configuration
echo "Performance Monitoring Configuration:"

# Error rate threshold (should be low for production)
error_threshold=${PERFORMANCE_ALERT_THRESHOLD_ERROR_RATE:-"0.05"}
if (( $(echo "$error_threshold <= 0.1" | bc -l) )); then
  echo "‚úÖ Error rate threshold: $error_threshold (good)"
else
  echo "‚ö†Ô∏è  Error rate threshold: $error_threshold (high for production)"
fi

# Response time threshold (should be reasonable)
response_threshold=${PERFORMANCE_ALERT_THRESHOLD_RESPONSE_TIME:-"5000"}
if (( response_threshold <= 10000 )); then
  echo "‚úÖ Response time threshold: ${response_threshold}ms (good)"
else
  echo "‚ö†Ô∏è  Response time threshold: ${response_threshold}ms (high for production)"
fi

# Data retention (should be appropriate for storage)
retention_hours=${PERFORMANCE_RETENTION_HOURS:-"168"}
retention_days=$((retention_hours / 24))
echo "‚ÑπÔ∏è  Performance data retention: $retention_hours hours ($retention_days days)"

# Memory limits
max_operations=${PERFORMANCE_MAX_OPERATIONS_IN_MEMORY:-"10000"}
echo "‚ÑπÔ∏è  Max operations in memory: $max_operations"
```

#### Health Check Validation
```bash
# Validate health check configuration
health_port=${HEALTH_CHECK_PORT:-"3000"}
echo "Health check port: $health_port"

# Test if port is available (basic check)
if command -v netstat > /dev/null 2>&1; then
  if netstat -an | grep -q ":$health_port.*LISTEN"; then
    echo "‚ö†Ô∏è  Port $health_port is already in use"
  else
    echo "‚úÖ Port $health_port is available"
  fi
fi

# Analytics dashboard (optional)
if [ "$ENABLE_ANALYTICS_DASHBOARD" = "true" ]; then
  analytics_port=${ANALYTICS_DASHBOARD_PORT:-"3001"}
  echo "‚úÖ Analytics dashboard enabled on port $analytics_port"
else
  echo "‚ÑπÔ∏è  Analytics dashboard disabled"
fi
```

### 6. Load Testing Validation

#### Basic Load Test Script
```bash
# Create a basic load test script
cat > load-test.sh << 'EOF'
#!/bin/bash

HEALTH_URL="http://localhost:${HEALTH_CHECK_PORT:-3000}/health"
CONCURRENT_REQUESTS=10
TOTAL_REQUESTS=100
SUCCESS_COUNT=0
FAILED_COUNT=0
TOTAL_TIME=0

echo "Starting load test..."
echo "URL: $HEALTH_URL"
echo "Concurrent requests: $CONCURRENT_REQUESTS"
echo "Total requests: $TOTAL_REQUESTS"
echo ""

# Function to make a request and measure time
make_request() {
  local start_time=$(date +%s%3N)
  if curl -s -f "$HEALTH_URL" > /dev/null 2>&1; then
    local end_time=$(date +%s%3N)
    local duration=$((end_time - start_time))
    echo "SUCCESS: ${duration}ms"
    return 0
  else
    echo "FAILED"
    return 1
  fi
}

# Run concurrent requests
for ((i=1; i<=TOTAL_REQUESTS; i+=CONCURRENT_REQUESTS)); do
  echo "Batch $((i/CONCURRENT_REQUESTS + 1))..."
  
  # Start concurrent requests
  for ((j=0; j<CONCURRENT_REQUESTS && i+j<=TOTAL_REQUESTS; j++)); do
    make_request &
  done
  
  # Wait for batch to complete
  wait
  
  # Small delay between batches
  sleep 1
done

echo ""
echo "Load test completed!"
EOF

chmod +x load-test.sh
```

#### Performance Metrics Collection
```bash
# Create performance monitoring test
cat > performance-test.sh << 'EOF'
#!/bin/bash

echo "üîç Performance Metrics Collection Test"
echo "====================================="

# Test performance monitoring service availability
if [ -f "src/services/performance-monitoring.service.ts" ]; then
  echo "‚úÖ Performance monitoring service available"
else
  echo "‚ùå Performance monitoring service not found"
  exit 1
fi

# Test CLI performance commands (if available)
if [ -f "src/cli/performance-cli.ts" ]; then
  echo "‚úÖ Performance CLI available"
  echo "üìä Testing performance commands..."
  
  # Note: These would require the service to be running
  echo "  - Performance stats: npm run perf:stats"
  echo "  - Generate dashboard: npm run perf:dashboard"
  echo "  - Export metrics: npm run perf:export"
else
  echo "‚ÑπÔ∏è  Performance CLI not found (optional)"
fi

# Test metrics endpoint (requires running service)
METRICS_URL="http://localhost:${HEALTH_CHECK_PORT:-3000}/metrics"
echo "üìà Testing metrics endpoint: $METRICS_URL"

# This would only work if the service is running
# curl -s "$METRICS_URL" > /dev/null && echo "‚úÖ Metrics endpoint responsive" || echo "‚ÑπÔ∏è  Metrics endpoint not available (service not running)"

echo ""
echo "Performance test configuration validated!"
EOF

chmod +x performance-test.sh
```

### 7. Security Validation

#### Security Checklist Script
```bash
cat > security-check.sh << 'EOF'
#!/bin/bash

echo "üîí Security Validation Checklist"
echo "==============================="

# Check for sensitive files that shouldn't be in production
sensitive_files=(".env" ".env.local" ".env.development" "*.log" "*.key" "*.pem")
echo "üîç Checking for sensitive files..."

found_sensitive=false
for pattern in "${sensitive_files[@]}"; do
  if ls $pattern 1> /dev/null 2>&1; then
    echo "‚ö†Ô∏è  Found sensitive files: $pattern"
    found_sensitive=true
  fi
done

if [ "$found_sensitive" = false ]; then
  echo "‚úÖ No sensitive files found in root directory"
fi

# Check environment variable security
echo ""
echo "üîë Validating environment variables..."

# Check for placeholder values
sensitive_vars=("DISCORD_TOKEN" "GEMINI_API_KEY" "OPENAI_API_KEY" "ANTHROPIC_API_KEY")
for var in "${sensitive_vars[@]}"; do
  value="${!var}"
  if [ -n "$value" ]; then
    if [[ "$value" == *"your_"* ]] || [[ "$value" == *"example"* ]]; then
      echo "‚ùå $var contains placeholder value"
    elif [ ${#value} -lt 10 ]; then
      echo "‚ö†Ô∏è  $var appears too short (length: ${#value})"
    else
      echo "‚úÖ $var is properly configured"
    fi
  else
    echo "‚ÑπÔ∏è  $var not set"
  fi
done

# Check file permissions (Unix-like systems)
echo ""
echo "üìÅ Checking file permissions..."

critical_files=("src/index.ts" "package.json" "prisma/schema.prisma")
for file in "${critical_files[@]}"; do
  if [ -f "$file" ]; then
    perms=$(stat -c "%a" "$file" 2>/dev/null || stat -f "%Lp" "$file" 2>/dev/null)
    if [ -n "$perms" ]; then
      echo "‚ÑπÔ∏è  $file: $perms"
    else
      echo "‚ÑπÔ∏è  $file: permissions check not available"
    fi
  fi
done

# Check for common security configurations
echo ""
echo "üõ°Ô∏è  Security configuration checks..."

# Rate limiting
if [ -n "$RATE_LIMIT_MAX_REQUESTS" ]; then
  echo "‚úÖ Rate limiting configured: $RATE_LIMIT_MAX_REQUESTS requests"
else
  echo "‚ÑπÔ∏è  Rate limiting not explicitly configured"
fi

# Content filtering
if [ "$CONTENT_FILTER_ENABLED" = "true" ]; then
  echo "‚úÖ Content filtering enabled"
else
  echo "‚ÑπÔ∏è  Content filtering not enabled"
fi

echo ""
echo "Security check completed!"
EOF

chmod +x security-check.sh
```

### 8. Integration Testing

#### Service Integration Test
```bash
# Create integration test script
cat > integration-test.js << 'EOF'
const { execSync } = require('child_process');
const fs = require('fs');

async function testServiceIntegration() {
  console.log('üîß Service Integration Test');
  console.log('===========================');
  
  // Test TypeScript compilation
  try {
    execSync('npx tsc --noEmit', { stdio: 'pipe' });
    console.log('‚úÖ TypeScript compilation successful');
  } catch (error) {
    console.log('‚ùå TypeScript compilation failed');
    console.log(error.stdout?.toString() || error.message);
    return false;
  }
  
  // Test Prisma client generation
  try {
    execSync('npx prisma generate', { stdio: 'pipe' });
    console.log('‚úÖ Prisma client generation successful');
  } catch (error) {
    console.log('‚ùå Prisma client generation failed');
    return false;
  }
  
  // Test service imports (static analysis)
  const coreServicePath = 'src/services/core-intelligence.service.ts';
  if (fs.existsSync(coreServicePath)) {
    const serviceContent = fs.readFileSync(coreServicePath, 'utf8');
    
    // Check for key imports
    const requiredImports = [
      'PerformanceMonitoringService',
      'EnhancedLangfuseService',
      'SentimentAnalysisService',
      'ContextMemoryService'
    ];
    
    let importCount = 0;
    for (const importName of requiredImports) {
      if (serviceContent.includes(importName)) {
        console.log(`‚úÖ ${importName} import found`);
        importCount++;
      } else {
        console.log(`‚ö†Ô∏è  ${importName} import not found`);
      }
    }
    
    const importPercentage = (importCount / requiredImports.length) * 100;
    console.log(`üìä Service integration: ${importPercentage.toFixed(1)}% (${importCount}/${requiredImports.length})`);
  }
  
  console.log('\nIntegration test completed!');
  return true;
}

// Run if called directly
if (require.main === module) {
  testServiceIntegration().catch(console.error);
}
EOF
```

## Production Deployment Checklist

### Pre-Deployment Checklist

```bash
# Complete pre-deployment validation
echo "üöÄ Pre-Deployment Checklist"
echo "=========================="

# 1. Run full validation script
echo "1. Running production validation script..."
if node scripts/production-validation.js; then
  echo "‚úÖ Production validation passed"
else
  echo "‚ùå Production validation failed - fix issues before deploying"
  exit 1
fi

# 2. Build application
echo "2. Building application..."
if npm run build; then
  echo "‚úÖ Application build successful"
else
  echo "‚ùå Application build failed"
  exit 1
fi

# 3. Run tests
echo "3. Running tests..."
if npm test; then
  echo "‚úÖ Tests passed"
else
  echo "‚ùå Tests failed"
  exit 1
fi

# 4. Check Docker configuration (if using Docker)
if [ -f "docker-compose.yml" ]; then
  echo "4. Validating Docker configuration..."
  if docker-compose config > /dev/null 2>&1; then
    echo "‚úÖ Docker Compose configuration valid"
  else
    echo "‚ùå Docker Compose configuration invalid"
    exit 1
  fi
fi

echo ""
echo "üéâ Pre-deployment validation completed successfully!"
echo "Ready for production deployment."
```

### Post-Deployment Validation

```bash
# Post-deployment health check
echo "üè• Post-Deployment Health Check"
echo "==============================="

HEALTH_URL="http://localhost:${HEALTH_CHECK_PORT:-3000}/health"
METRICS_URL="http://localhost:${HEALTH_CHECK_PORT:-3000}/metrics"
MAX_RETRIES=30
RETRY_INTERVAL=10

echo "Waiting for service to start..."

# Wait for service to be healthy
for i in $(seq 1 $MAX_RETRIES); do
  if curl -s -f "$HEALTH_URL" > /dev/null 2>&1; then
    echo "‚úÖ Service is healthy (attempt $i)"
    break
  else
    echo "‚è≥ Waiting for service... (attempt $i/$MAX_RETRIES)"
    if [ $i -eq $MAX_RETRIES ]; then
      echo "‚ùå Service failed to start within expected time"
      exit 1
    fi
    sleep $RETRY_INTERVAL
  fi
done

# Test health endpoint response
echo ""
echo "üìä Testing health endpoint..."
health_response=$(curl -s "$HEALTH_URL")
if echo "$health_response" | grep -q "\"status\":\"ok\""; then
  echo "‚úÖ Health endpoint returns OK status"
else
  echo "‚ö†Ô∏è  Health endpoint response unexpected: $health_response"
fi

# Test metrics endpoint
echo ""
echo "üìà Testing metrics endpoint..."
if curl -s "$METRICS_URL" | head -5 > /dev/null; then
  echo "‚úÖ Metrics endpoint responding"
else
  echo "‚ö†Ô∏è  Metrics endpoint not responding"
fi

# Test analytics dashboard (if enabled)
if [ "$ENABLE_ANALYTICS_DASHBOARD" = "true" ]; then
  DASHBOARD_URL="http://localhost:${ANALYTICS_DASHBOARD_PORT:-3001}"
  echo ""
  echo "üìä Testing analytics dashboard..."
  if curl -s -f "$DASHBOARD_URL" > /dev/null 2>&1; then
    echo "‚úÖ Analytics dashboard responding"
  else
    echo "‚ö†Ô∏è  Analytics dashboard not responding"
  fi
fi

echo ""
echo "üéâ Post-deployment validation completed!"
```

## Continuous Monitoring

### Production Monitoring Setup

```bash
# Setup production monitoring alerts
cat > monitoring-setup.sh << 'EOF'
#!/bin/bash

echo "üìä Production Monitoring Setup"
echo "=============================="

# Create monitoring configuration
cat > monitoring-config.json << 'JSON'
{
  "alerts": {
    "errorRate": {
      "threshold": 0.05,
      "window": "5m",
      "severity": "critical"
    },
    "responseTime": {
      "threshold": 5000,
      "window": "5m", 
      "severity": "warning"
    },
    "throughput": {
      "threshold": 200,
      "window": "1m",
      "severity": "info"
    }
  },
  "retention": {
    "metrics": "7d",
    "logs": "30d",
    "traces": "3d"
  },
  "dashboard": {
    "refreshInterval": 30000,
    "autoRefresh": true
  }
}
JSON

echo "‚úÖ Monitoring configuration created"

# Setup log rotation (Linux/Unix)
if command -v logrotate > /dev/null 2>&1; then
  cat > /etc/logrotate.d/chatterbot << 'LOGROTATE'
/var/log/chatterbot/*.log {
  daily
  missingok
  rotate 30
  compress
  notifempty
  create 644 chatterbot chatterbot
  postrotate
    systemctl reload chatterbot
  endscript
}
LOGROTATE
  echo "‚úÖ Log rotation configured"
fi

echo "Production monitoring setup completed!"
EOF

chmod +x monitoring-setup.sh
```

## Troubleshooting Common Issues

### Service Startup Issues
```bash
# Check service startup logs
docker-compose logs chatterbot

# Check health endpoint
curl http://localhost:3000/health

# Check environment variables
docker-compose exec chatterbot env | grep -E "(DISCORD|GEMINI|OPENAI)"

# Check database connectivity
docker-compose exec chatterbot npx prisma db push --accept-data-loss
```

### Performance Issues
```bash
# Check performance metrics
curl http://localhost:3000/metrics

# Monitor resource usage
docker stats chatterbot

# Check performance monitoring logs
docker-compose exec chatterbot npm run perf:stats

# Generate performance dashboard
docker-compose exec chatterbot npm run perf:dashboard
```

### Feature Flag Issues
```bash
# Validate feature flag configuration
node -e "
const flags = [
  'ENABLE_ENHANCED_INTELLIGENCE',
  'ENABLE_PERFORMANCE_MONITORING',
  'ENABLE_SENTIMENT_ANALYSIS'
];
flags.forEach(flag => {
  console.log(\`\${flag}: \${process.env[flag] || 'not set'}\`);
});
"

# Test feature flag functionality
npm run test:feature-flags
```

## Deployment Validation Summary

The production deployment validation ensures:

1. ‚úÖ **Environment**: All required variables configured
2. ‚úÖ **Services**: 17 AI enhancement services available and configured
3. ‚úÖ **Performance**: Monitoring thresholds and alerting properly set
4. ‚úÖ **Database**: Connectivity, migrations, and data persistence
5. ‚úÖ **Security**: Credentials secure, no sensitive files exposed
6. ‚úÖ **Load Handling**: Concurrent request processing validated
7. ‚úÖ **Integration**: All services properly integrated and communicating
8. ‚úÖ **Monitoring**: Health checks, metrics, and observability active

Use the automated `scripts/production-validation.js` script for comprehensive validation, or run individual validation procedures as needed for specific areas of concern.